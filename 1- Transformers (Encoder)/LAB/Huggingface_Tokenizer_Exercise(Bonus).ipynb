{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec47c97d",
   "metadata": {},
   "source": [
    "# Exercise: Working with Hugging Face Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7668610a",
   "metadata": {},
   "source": [
    "### Part 1: Basic Tokenization with Hugging Face Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd04b75",
   "metadata": {},
   "source": [
    "\n",
    "1. Install the Hugging Face `transformers` library:\n",
    "   ```bash\n",
    "   !pip install transformers\n",
    "   ```\n",
    "\n",
    "2. Choose a pre-trained tokenizer from Hugging Face’s model hub (e.g., `bert-base-uncased`, `gpt2`, etc.) and tokenize a piece of text:\n",
    "   \n",
    "   **Task**: Load the tokenizer and tokenize the sentence: `\"T5 is the greatest data science boot-camp!\"`\n",
    "\n",
    "   Below is a code block where you can perform this task:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dffd763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e27c9634",
   "metadata": {},
   "source": [
    "\n",
    "### Part 2: Encoding and Decoding\n",
    "\n",
    "3. Use the same tokenizer to encode the sentence (convert to token IDs) and then decode it back to text.\n",
    "\n",
    "   **Task**: Encode the sentence and then decode it back to text.\n",
    "\n",
    "   Below is a code block where you can perform this task:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1292c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14a8df7c",
   "metadata": {},
   "source": [
    "\n",
    "### Bonus Challenge\n",
    "\n",
    "4. **Custom Tokenizer**: Use Hugging Face’s `tokenizers` library to train a custom tokenizer on a dataset.\n",
    "   \n",
    "   You are provided with a dataset containing multiple sentences. Train a custom tokenizer using these sentences.\n",
    "\n",
    "   Below is a code block to train the tokenizer:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30701893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b10db58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Provided dataset for the bonus challenge\n",
    "dataset = [\n",
    "    \"Transformers are amazing for NLP tasks.\",\n",
    "    \"Tokenization is essential for language models.\",\n",
    "    \"Byte Pair Encoding is a great subword tokenization algorithm.\",\n",
    "    \"Hugging Face makes it easy to work with pre-trained models.\",\n",
    "    \"Data science is the key to unlocking insights from data.\"\n",
    "]\n",
    "print(dataset)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd3ff36d",
   "metadata": {},
   "source": [
    "# Fine-tuning Question Answering Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605a111a",
   "metadata": {},
   "source": [
    "This exam will guide you through loading, preprocessing, and fine-tuning a pre-trained model for a question-answering task using a dataset. Follow the steps carefully.\n",
    "\n",
    "### Model and Dataset Information\n",
    "\n",
    "For this task, you will be working with the following:\n",
    "\n",
    "- **Model Checkpoint**: Use the pre-trained model checkpoint `distilbert-base-cased` for both the model and tokenizer.\n",
    "- **Dataset**: You will be using the `christti/squad-augmented-v2` dataset. Ensure to load and preprocess the dataset correctly for training and evaluation.\n",
    "\n",
    "**Note:**\n",
    "- Any additional steps or methods you include that improve or enhance the results will be rewarded with bonus points if they are justified.\n",
    "- The steps outlined here are suggestions. You are free to implement alternative methods or approaches to achieve the task, as long as you explain the reasoning and the process at the bottom of the notebook.\n",
    "- You can use either TensorFlow or PyTorch for this task. If you prefer TensorFlow, feel free to use it when working with Hugging Face Transformers.\n",
    "- The number of data samples you choose to work with is flexible. However, if you select a very low number of samples and the training time is too short, this could affect the evaluation of your work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a124cdfe",
   "metadata": {},
   "source": [
    "## Step 1: Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e3d2ee",
   "metadata": {},
   "source": [
    "Load the dataset and split it into training and test sets. Use 20% of the data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a316837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a03cdcf7",
   "metadata": {},
   "source": [
    "## Step 2: Load the Pretrained Tokenizer and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d09dc46",
   "metadata": {},
   "source": [
    "Use the model and tokenizer for the question-answering task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ccbb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31a73963",
   "metadata": {},
   "source": [
    "## Step 3: Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d84cb15",
   "metadata": {},
   "source": [
    "Define a function to preprocess the dataset by tokenizing both the context and the question. The function will also calculate the start and end positions of the answers. In the tokenizer you might face a problem if you use `truncation=True` so consider using `truncation='only_first'` if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9218b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc7ff9c8",
   "metadata": {},
   "source": [
    "## Step 4: Define Training Arguments and Initialize the Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a55e7d4",
   "metadata": {},
   "source": [
    "Set up the training configuration with parameters like learning rate, batch size, and number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad7aa6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "746d2fa8",
   "metadata": {},
   "source": [
    "## Step 5: Fine-tune the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1189ec73",
   "metadata": {},
   "source": [
    "Run the training process using the initialized trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda07d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1df1eaf4",
   "metadata": {},
   "source": [
    "## Step 6: Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57095255",
   "metadata": {},
   "source": [
    "Once the model is trained, perform inference by answering a question based on a context. Use the tokenizer to process the input, and then feed it into the model to get the predicted answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caa026e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
